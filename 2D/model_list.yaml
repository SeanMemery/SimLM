models: [
  "psmathur_orca_mini_3b",
  "meta-llama/Llama-2-7b-hf",
  "meta-llama/Llama-2-13b-hf",
  "meta-llama/Llama-2-70b-hf",
  "meta-llama/Llama-2-7b-chat-hf",
  "meta-llama/Llama-2-13b-chat-hf",
  "meta-llama/Llama-2-70b-chat-hf",
  "lmsys/vicuna-7b-v1.5",
  "lmsys/vicuna-13b-v1.5",
  "lmsys/vicuna-33b-v1.3",
  "tiiuae/falcon-7b",
  "tiiuae/falcon-40b",
  "tiiuae/falcon-180B",
  "WizardLM/WizardCoder-1B-V1.0",
  "WizardLM/WizardCoder-3B-V1.0",
  "WizardLM/WizardCoder-Python-7B-V1.0",
  "WizardLM/WizardCoder-Python-13B-V1.0",
  "WizardLM/WizardCoder-15B-V1.0",
  "WizardLM/WizardCoder-Python-34B-V1.0",
  "WizardLM/WizardLM-70B-V1.0",
  "EleutherAI/pythia-70m-deduped-v0",
  "EleutherAI/pythia-160m-deduped-v0",
  "EleutherAI/pythia-410m-deduped-v0",
  "EleutherAI/pythia-1b-deduped-v0",
  "EleutherAI/pythia-1.4b-deduped-v0",
  "EleutherAI/pythia-2.8b-deduped-v0",
  "EleutherAI/pythia-6.9b-deduped-v0",
  "EleutherAI/pythia-12b-deduped-v0",
  "chat-bison",
  "chat-bison-32k",
]
palm: [
  "chat-bison",
  "chat-bison-32k",
]
llama2: [
  "meta-llama/Llama-2-7b-hf",
  "meta-llama/Llama-2-13b-hf",
  "meta-llama/Llama-2-70b-hf",
]
llama2-chat: [
  "meta-llama/Llama-2-7b-chat-hf",
  "meta-llama/Llama-2-13b-chat-hf",
  "meta-llama/Llama-2-70b-chat-hf",
]
vicuna: [
  "lmsys/vicuna-7b-v1.5",
  "lmsys/vicuna-13b-v1.5",
  "lmsys/vicuna-33b-v1.3",
]
falcon: [
  "tiiuae/falcon-7b",
  "tiiuae/falcon-40b",
  "tiiuae/falcon-180B",
]
wizardlm: [
  "WizardLM/WizardCoder-1B-V1.0",
  "WizardLM/WizardCoder-3B-V1.0",
  "WizardLM/WizardCoder-3B-V1.0",
  "WizardLM/WizardCoder-Python-7B-V1.0",
  "WizardLM/WizardCoder-Python-13B-V1.0",
  "WizardLM/WizardCoder-15B-V1.0",
  "WizardLM/WizardCoder-Python-34B-V1.0",
  "WizardLM/WizardLM-70B-V1.0",
]
pythia: [
  "EleutherAI/pythia-70m-deduped-v0",
  "EleutherAI/pythia-160m-deduped-v0",
  "EleutherAI/pythia-410m-deduped-v0",
  "EleutherAI/pythia-1b-deduped-v0",
  "EleutherAI/pythia-1.4b-deduped-v0",
  "EleutherAI/pythia-2.8b-deduped-v0",
  "EleutherAI/pythia-6.9b-deduped-v0",
  "EleutherAI/pythia-12b-deduped-v0",
]
extra: [
  "Llama-2-7B-32K-Instruct",
  "psmathur_orca_mini_3b",
  "gpt-4",
  "gpt-3.5-turbo",
]
focus: [
  #"meta-llama/Llama-2-70b-chat-hf",
  #"gpt-4",
  #"gpt-3.5-turbo",
  #"chat-bison",
  #"text-bison",
  "gemini-pro",
]
exp1: [
  "tiiuae/falcon-180B-chat",
  "meta-llama/Llama-2-70b-chat-hf",
]
exp2: [
  # "tiiuae/falcon-180B-chat",
  # "meta-llama/Llama-2-70b-chat-hf",
  # "gpt-4",
  "gpt-3.5-turbo",
]

test: [
  #"meta-llama/Llama-2-7b-chat-hf",
  "meta-llama/Llama-2-13b-chat-hf",
  #"meta-llama/Llama-2-70b-chat-hf",
  #"chat-bison",
  #"gpt-4",
  #"gpt-4-1106-preview",
  #"tiiuae/falcon-7b",
  #"EleutherAI/pythia-70m-deduped-v0",
  #"gpt-3.5-turbo",
  #"uukuguy_speechless-llama2-hermes-orca-platypus-wizardlm-13b"
]
